#!/bin/bash


# Relevant files to access
src="$(pwd)"
dwi_data=data
dwi=postmc_dstriped-dwi300.mif
bet_mask=mask_T2w_brainmask_processed.nii.gz
warps=dhcp_neo_dMRI_derived
warps_in_40wk=from-dmrishard_to-extdhcp40wk_mode-image.mif.gz
wm_response=dHCP_atlas_v2.1_rf_wm.dhsfa015_44 # this response function is generated from 21 WM response functions from subjects aged 44.1 weeks
csf_response=dHCP_atlas_v2.1_rf_csf.dhsfa015 # this response function is generated by averaging all CSF response functions.
#subjects_list=subjects_list.txt
#subjects_list=subject_lists_term_preterm.txt
#subjects_list=available_subjects_PRSPCA.txt
#subjects_list=available_subjects_PRSPCA_test.txt
#subjects_list=available_subjects_PRSrisk.txt
#subjects_list=available_subjects_PRSPt001.txt
#subjects_list=available_subjects_APOE.txt
subjects_list=available_subjects_ZNF804A.txt
#output_folder=output_PRSrisk/
output_folder=output
#individual_fods_output=individual_fods # this file is on dhcp-reconstruction/Hai/output
individual_fods_output=output
# Relevant files for generate_ID_list.sh
rf_data="dhcp_neo_dMRI_derived"
participants_info="dHCP_participant_info.csv"
usable_subjects="usable_subj.txt"
all_available_IDs=all_available_IDs.txt
usable_subj=usable_subj.txt
euro_SCZ_PRS_term="european_volumetric_df_rel3_batch2.csv"
# Relevant files for calculate_fods.sh
mask=mask.mif
wm_fod=wm_fod.mif
csf_fod=csf_fod.mif
wm_norm_fod=wm_norm_fod.mif
csf_norm_fod=csf_norm_fod.mif
warped_mask_in_dHCP_40wk=warped_mask_in_dHCP_40wk.mif
warped_wm_fod_in_dHCP_40wk=warped_wm_fod_in_dHCP_40wk.mif

# Relevant files for compute_average_masks_and_fods.sh
warped_mask_average=warped_mask_average.mif
warped_wm_fod_average=warped_wm_fod_average.mif
fixel_mask=fixel_mask

# Relevant files for calculate_fixel_metrics.sh
native2average_warp=native2average_warp.mif
average2native_warp=average2native_warp.mif

fod_in_template_space_NOT_REORIENTED=fod_in_template_space_NOT_REORIENTED.mif
fixel_in_template_space_NOT_REORIENTED=fixel_in_template_space_NOT_REORIENTED
fd=fd.mif
fixel_in_template_space=fixel_in_template_space

all_subj_fd=all_subj_fd 
all_subj_fc=all_subj_fc
all_subj_log_fc=all_subj_log_fc
all_subj_fdc=all_subj_fdc

# Relevant files for 5tt.sh
templates="${src}/atlas/templates"
KANA_in_template_space="${templates}/KANA_in_template_space_2.nii.gz"
Tissue_segmented="${templates}/week40_tissue_dseg.nii.gz"
Tissue_segmented_probseg="${templates}/week40_tissue_probseg.nii.gz"

#6 = cerbellum 7 and 8 = brain stem and deep gray matter
KANA_DGM=KANA_DGM.mif
regrid_KANA_in_template=regrid_KANA_in_template_space.mif
regrid_Tissue_segmented=regrid_Tissue_segmented.mif
regrid_Tissue_probseg_segmented=regrid_Tissue_segmented.mif
output_5TT=5TT
wm=wm.mif
gm=gm.mif
dgm=dgm.mif
csf=csf.mif
path=path.mif
image_5TT=5TT.mif

# Relevant files for tractography.sh
output_tractography=tractography
number_of_streamlines=20000000
tracts="tracts_${number_of_streamlines}.tck"
angle=22.5
maxlen=250
minlen=10
power=1.0
reduced_number_of_streamlines=2000000
reduced_tracts=reduced_tracts_${reduced_number_of_streamlines}.tck
fba_output=fba
ffixel_matrix=ffixel_matrix
#Relevant files for perform_fba.sh

id_file=id_file.txt
design_matrix=design_matrix.txt
contrast_matrix=contrast_matrix.txt

stats_fd=stats_fd
stats_log_fc=stats_log_fc
stats_fdc=stats_fdc

summary_contrast=summary_contrast.txt

#Relevant files for calculate_dti.sh
diffusion_tensor=diffusion_tensor.mif
dt_fa=dt_fa.mif
dt_adc=dt_adc.mif
dt_rd=dt_rd.mif
dt_ad=dt_ad.mif

dti_stats=dti_stats

DTI_in_template_space=DTI_in_template_space

#Relevant files for perform_aba.sh

common_wm_fod_40weeks_by_Alena=$src/wm_parcellation/parcellation_maps_05mm/common_space_ODF_4000.mif
native2wm_parc_warp=native2wm_parc_warp.mif
wm_parc2native_warp=wm_parc2native_warp.mif
wm_parcellation_by_Alena=$src/wm_parcellation/parcellation_maps_05mm/reference-05mm-WM-parcellation.nii.gz
subject_wm_parc=wm_parc_in_subject_space.mif

#Relevant files for perform_tbss.sh

bval=postmc_dstriped-dwi.bval
bvec=postmc_dstriped-dwi.bvec
all_subjects_dti=all_subjects_dti.txt
dwi_nii=postmc_dstriped-dwi.nii.gz
ID_template=ID_template.txt
tbss=tbss
DTI_TK_processed=DTI_TK_processed
stats_folder=stats

#Relevant file for generating tracts
individual_tracts=individual_tracts
interhemispheric_exclude=interhemispheric_exclude.mif
wm_tracts=wm_tracts.txt

tracts_streamlines=10000000
reduced_tracts_streamlines=100000
sift_tracts="sifted_${tracts_streamlines}.tck"

#relevant for perform_fba_wm.sh

tract_fixel_mask=tract_fixel_mask

fmi=fmi
fma=fma
cing_D_L=cing_D_L
cing_D_R=cing_D_R
uf_L=uf_L
uf_R=uf_R
cc=cc

tract_to_examine=( $cc )
fba_measures_to_examine=( fd fdc log_fc )


#relevant for glass_brain.sh
glass_brain_folder=glass_brain
mask_threshold=mask_threshold.mif
glass_brain=glass_brain.mif

set -e

. support_functions.sh

#. generate_ID_list.sh

#if [ ! -d data ]; then
#    echo "dhcp-pipeline-data not yet mounted"
#    sudo mount -t cifs //isi01/dhcp-pipeline-data /home/lh20/dhcp-pipeline-data/ -o username=lh20,domain=isd,iocharset=utf8,vers=2.1
#    echo "dhcp-pipeline-data mounted"
#fi
#

# build list of subjects:
ID_list=()
while read subj; do
  # skip if empty:
  if [ "x$subj" == "x" ]; then continue; fi

  # split line into components to get folder name:
  IFS=',' read -ra subj <<< $subj
  ID_list+=(${subj[0]})
done < $subjects_list

cd $src
#. calculate_fods.sh
cd $src
#. compute_average_masks_and_fods.sh
cd $src
#. calculate_fixel_metrics.sh
cd $src
#. gen5tt.sh
cd $src
#. tractography.sh
cd $src
#. perform_fba.sh
cd $src
#. calculate_dti.sh
cd $src
. perform_tbss.sh
cd $src
#. genwmtracts.sh
cd $src
#. perform_fba_wm.sh
cd $src
#. glass_brain.sh
